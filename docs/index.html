<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Musical Transformer Interpretability Research</title>
    <style>
        body {
            font-family: 'Georgia', serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 2rem;
            line-height: 1.6;
            background-color: #fafafa;
        }
        h1 { color: #2c3e50; text-align: center; }
        article {
            margin: 2rem 0;
            padding: 1.5rem;
            background: white;
            border: 1px solid #e1e1e1;
            border-radius: 8px;
        }
        article h2 a {
            color: #3498db;
            text-decoration: none;
        }
        article h2 a:hover {
            text-decoration: underline;
        }
        .metadata {
            color: #666;
            font-size: 0.9rem;
        }
        footer {
            margin-top: 3rem;
            padding-top: 1rem;
            border-top: 1px solid #e1e1e1;
            font-size: 0.9rem;
            color: #666;
            text-align: center;
        }
    </style>
</head>
<body>
    <h1>Musical Transformer Interpretability Research</h1>

    <section>

<article>
    <h2><a href="essay.html">Substrate Melodies: Probing Musical Understanding Through Transformer Confusion</a></h2>
    <p class="metadata">
        January 21, 2026 |
        5,722 words |
        28 minutes
    </p>
    <p>An exploration of how transformer models process ABC notation music, using interpretability metrics to map the boundaries of machine musical understanding.</p>
</article>

<article>
    <h2><a href="perplexity.html">Perplexity: The Language Model's Measure of Surprise</a></h2>
    <p class="metadata">
        January 21, 2026 |
        18 minutes
    </p>
    <p>A deep dive into perplexity as a metric for evaluating language model understanding, exploring its mathematical foundations and practical applications to musical analysis.</p>
</article>

<article>
    <h2><a href="attention-entropy.html">Attention Entropy: Measuring Focus in Transformer Networks</a></h2>
    <p class="metadata">
        January 21, 2026 |
        20 minutes
    </p>
    <p>Understanding how attention entropy reveals model behavior through the lens of information-theoretic analysis, with insights from musical transformer experiments.</p>
</article>

<article>
    <h2><a href="surprisal.html">Surprisal: Information-Theoretic Analysis of Sequential Prediction</a></h2>
    <p class="metadata">
        January 21, 2026 |
        22 minutes
    </p>
    <p>Exploring surprisal as a token-level metric for understanding prediction difficulty, connecting information theory to both machine learning and human cognition.</p>
</article>

<article>
    <h2><a href="music-fundamentals.html">The Language of Music: A Holistic Guide to Musical Concepts</a></h2>
    <p class="metadata">
        January 21, 2026 |
        35 minutes
    </p>
    <p>A comprehensive guide to musical theory—from ABC notation and scales to voice leading and form—providing the conceptual foundation for understanding how transformers process music.</p>
</article>

    </section>

    <footer>
        <h3>About</h3>
        <p>
            Brian Edwards<br>
            brian.mabry.edwards@gmail.com<br>
        </p>
        <p>Built with Claude Code (Claude Opus 4.5)</p>
    </footer>
</body>
</html>
