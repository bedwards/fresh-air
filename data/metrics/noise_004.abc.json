{
  "filename": "noise_004.abc",
  "model": "phi4:14b",
  "timestamp": "2026-01-21T09:46:53.557226",
  "token_count": 166,
  "perplexity": {
    "overall": 1.7465,
    "per_token": [
      3.5892,
      1.5331,
      1.0,
      1.0456,
      1.6806,
      3.6721,
      1.2337,
      3.332,
      5.4307,
      2.4047,
      1.9644,
      1.9406,
      1.0,
      1.0362,
      2.4026,
      2.4161,
      1.0153,
      1.649,
      5.14,
      1.0034,
      1.7707,
      2.6004,
      1.0737,
      1.0089,
      1.1033,
      2.6892,
      1.2875,
      2.1442,
      1.8146,
      8.001,
      2.0844,
      4.1046,
      1.0667,
      1.4777,
      1.1569,
      2.2902,
      1.0004,
      1.2139,
      1.493,
      4.7545,
      1.721,
      3.8374,
      1.0765,
      1.4028,
      1.1508,
      1.6512,
      1.0002,
      1.1228,
      1.5611,
      4.365,
      2.1921,
      3.9856,
      1.0674,
      1.633,
      1.0656,
      1.2503,
      1.0,
      1.0771,
      1.3981,
      3.8131,
      2.4325,
      1.7855,
      1.4214,
      3.1831,
      3.6425,
      2.2017,
      1.7829,
      1.0062,
      1.6286,
      2.1547,
      1.8334,
      5.831,
      1.0697,
      1.4264,
      1.0843,
      1.6537,
      1.0005,
      1.1097,
      1.6041,
      3.0512,
      2.82,
      5.2966,
      1.0821,
      1.5493,
      1.0916,
      1.39,
      1.0001,
      1.1099,
      1.4801,
      4.2721,
      2.2031,
      6.1855,
      2.7187,
      1.3588,
      1.0001,
      1.2628,
      1.2183,
      5.0656,
      1.0646,
      3.6614,
      2.2442,
      5.7741,
      1.1703,
      1.4586,
      1.189,
      1.3704,
      1.0027,
      1.0293,
      1.9704,
      1.8833,
      2.2848,
      3.8808,
      1.0793,
      1.7503,
      1.0674,
      1.4274,
      1.0002,
      1.1057,
      10.2392,
      1.0214,
      1.9659,
      2.9727,
      1.0413,
      1.4539,
      1.1213,
      1.8397,
      1.0002,
      1.1248,
      1.576,
      3.0302,
      2.0914,
      5.3464,
      1.1991,
      1.3356,
      1.0936,
      1.8202,
      1.0008,
      1.1906,
      1.6381,
      2.0103,
      1.691,
      2.9692,
      1.0943,
      1.4574,
      1.1251,
      1.9079,
      1.0007,
      1.1249,
      1.3755,
      2.736,
      1.5065,
      5.3293,
      1.7599,
      1.409,
      1.1536,
      1.3513,
      1.0004,
      1.1746,
      2.0001,
      2.749,
      2.0164,
      4.7359,
      1.1029,
      1.3669,
      1.1086,
      1.6283
    ],
    "max": 10.2392,
    "min": 1.0,
    "mean": 2.0567
  },
  "attention": {
    "mean_entropy": null,
    "per_layer": null,
    "per_head": null,
    "high_entropy_heads": [],
    "note": "Attention weights not available via Ollama API. Use transformers library with output_attentions=True for direct model access to attention patterns."
  },
  "surprisal": {
    "mean": 0.8045,
    "per_token": [
      1.8437,
      0.6164,
      0.0,
      0.0644,
      0.749,
      1.8766,
      0.303,
      1.7364,
      2.4411,
      1.2659,
      0.9741,
      0.9565,
      0.0,
      0.0514,
      1.2646,
      1.2727,
      0.0219,
      0.7215,
      2.3618,
      0.005,
      0.8243,
      1.3787,
      0.1026,
      0.0128,
      0.1418,
      1.4272,
      0.3645,
      1.1004,
      0.8597,
      3.0002,
      1.0596,
      2.0372,
      0.0931,
      0.5633,
      0.2102,
      1.1955,
      0.0005,
      0.2797,
      0.5782,
      2.2493,
      0.7833,
      1.9401,
      0.1063,
      0.4883,
      0.2027,
      0.7235,
      0.0003,
      0.1671,
      0.6425,
      2.126,
      1.1323,
      1.9948,
      0.0941,
      0.7075,
      0.0917,
      0.3223,
      0.0,
      0.1071,
      0.4835,
      1.931,
      1.2824,
      0.8363,
      0.5073,
      1.6704,
      1.8649,
      1.1386,
      0.8342,
      0.009,
      0.7036,
      1.1075,
      0.8745,
      2.5437,
      0.0973,
      0.5124,
      0.1168,
      0.7257,
      0.0007,
      0.1502,
      0.6817,
      1.6094,
      1.4957,
      2.4051,
      0.1139,
      0.6316,
      0.1264,
      0.4751,
      0.0001,
      0.1505,
      0.5657,
      2.095,
      1.1395,
      2.6289,
      1.4429,
      0.4424,
      0.0002,
      0.3366,
      0.2848,
      2.3407,
      0.0903,
      1.8724,
      1.1662,
      2.5296,
      0.2269,
      0.5446,
      0.2497,
      0.4546,
      0.0038,
      0.0416,
      0.9785,
      0.9133,
      1.1921,
      1.9563,
      0.1101,
      0.8076,
      0.0941,
      0.5134,
      0.0002,
      0.145,
      3.356,
      0.0305,
      0.9752,
      1.5718,
      0.0584,
      0.5399,
      0.1651,
      0.8795,
      0.0004,
      0.1696,
      0.6563,
      1.5994,
      1.0645,
      2.4186,
      0.262,
      0.4175,
      0.129,
      0.8641,
      0.0011,
      0.2517,
      0.712,
      1.0074,
      0.7579,
      1.5701,
      0.13,
      0.5434,
      0.17,
      0.932,
      0.001,
      0.1698,
      0.46,
      1.452,
      0.5912,
      2.414,
      0.8155,
      0.4946,
      0.2061,
      0.4343,
      0.0005,
      0.2321,
      1.0,
      1.4589,
      1.0118,
      2.2436,
      0.1414,
      0.4509,
      0.1487,
      0.7034
    ],
    "high_surprisal_tokens": []
  },
  "activations": {
    "per_layer_norm": null,
    "variance_per_layer": null,
    "note": "Internal activations not available via Ollama API. Use transformers library with output_hidden_states=True for direct model access to layer activations."
  },
  "comparative": {
    "baseline": "traditional_mean",
    "perplexity_zscore": 0.4949,
    "entropy_zscore": 0.5423,
    "surprisal_zscore": 0.5423,
    "outlier_flags": [],
    "classification": "statistically_normal",
    "interpretation": "This piece falls well within the normal range of the model's experience with musical notation. All metrics indicate familiar, predictable patterns."
  }
}