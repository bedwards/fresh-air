{
  "filename": "silence_003.abc",
  "model": "phi4:14b",
  "timestamp": "2026-01-21T09:47:09.594934",
  "token_count": 70,
  "perplexity": {
    "overall": 1.6281,
    "per_token": [
      2.3257,
      2.3999,
      1.052,
      3.3751,
      3.2048,
      2.4494,
      1.0002,
      1.3953,
      2.2968,
      4.2558,
      2.5564,
      1.0,
      1.1621,
      2.736,
      1.4775,
      1.0183,
      1.1228,
      1.5014,
      2.0145,
      1.0538,
      2.736,
      1.8065,
      1.0067,
      1.5668,
      1.0387,
      1.0839,
      1.0221,
      1.0001,
      1.0,
      1.6275,
      2.112,
      2.3495,
      1.7639,
      1.5031,
      1.004,
      1.3399,
      1.1492,
      1.0013,
      2.584,
      1.2374,
      2.281,
      2.6616,
      1.3619,
      1.4684,
      1.0872,
      1.96,
      1.0017,
      1.5876,
      1.1363,
      1.6354,
      2.4943,
      6.1518,
      1.2393,
      1.6111,
      1.2872,
      2.0367,
      1.0467,
      3.8829,
      2.947,
      1.0001,
      1.3203,
      1.5452,
      1.0,
      1.2393,
      2.2606,
      4.7513,
      1.1996,
      2.9895,
      1.0392,
      1.0
    ],
    "max": 6.1518,
    "min": 1.0,
    "mean": 1.8222
  },
  "attention": {
    "mean_entropy": null,
    "per_layer": null,
    "per_head": null,
    "high_entropy_heads": [],
    "note": "Attention weights not available via Ollama API. Use transformers library with output_attentions=True for direct model access to attention patterns."
  },
  "surprisal": {
    "mean": 0.7032,
    "per_token": [
      1.2177,
      1.2629,
      0.0732,
      1.755,
      1.6802,
      1.2924,
      0.0003,
      0.4805,
      1.1996,
      2.0894,
      1.3541,
      0.0,
      0.2168,
      1.4521,
      0.5631,
      0.0261,
      0.167,
      0.5863,
      1.0105,
      0.0756,
      1.4521,
      0.8532,
      0.0096,
      0.6478,
      0.0548,
      0.1162,
      0.0316,
      0.0001,
      0.0,
      0.7026,
      1.0786,
      1.2324,
      0.8188,
      0.588,
      0.0057,
      0.4221,
      0.2006,
      0.0018,
      1.3696,
      0.3073,
      1.1897,
      1.4123,
      0.4456,
      0.5543,
      0.1206,
      0.9709,
      0.0024,
      0.6668,
      0.1844,
      0.7096,
      1.3186,
      2.621,
      0.3095,
      0.688,
      0.3642,
      1.0262,
      0.0658,
      1.9571,
      1.5592,
      0.0001,
      0.4009,
      0.6278,
      0.0,
      0.3095,
      1.1767,
      2.2483,
      0.2625,
      1.5799,
      0.0554,
      0.0
    ],
    "high_surprisal_tokens": []
  },
  "activations": {
    "per_layer_norm": null,
    "variance_per_layer": null,
    "note": "Internal activations not available via Ollama API. Use transformers library with output_hidden_states=True for direct model access to layer activations."
  },
  "comparative": {
    "baseline": "traditional_mean",
    "perplexity_zscore": -0.3857,
    "entropy_zscore": -0.3657,
    "surprisal_zscore": -0.3657,
    "outlier_flags": [],
    "classification": "statistically_normal",
    "interpretation": "This piece falls well within the normal range of the model's experience with musical notation. All metrics indicate familiar, predictable patterns."
  }
}