{
  "filename": "noise_003.abc",
  "model": "phi4:14b",
  "timestamp": "2026-01-21T09:46:44.426421",
  "token_count": 150,
  "perplexity": {
    "overall": 1.6783,
    "per_token": [
      3.0388,
      2.0438,
      1.0,
      1.0723,
      2.3412,
      4.934,
      1.0035,
      1.8034,
      3.6209,
      1.3703,
      2.1014,
      2.0113,
      1.0,
      1.0532,
      2.2372,
      2.2089,
      1.5239,
      1.4873,
      2.2365,
      2.7194,
      1.5887,
      2.0623,
      1.0533,
      1.0225,
      1.3261,
      2.4373,
      1.9325,
      2.555,
      1.0191,
      1.0114,
      1.6617,
      1.8822,
      1.0243,
      1.3922,
      2.4227,
      2.7135,
      5.8512,
      2.1762,
      1.1581,
      2.715,
      1.5438,
      4.4425,
      1.1235,
      1.6447,
      1.0659,
      1.6292,
      1.0003,
      1.3199,
      1.1343,
      3.2274,
      1.7416,
      3.943,
      1.1424,
      1.472,
      1.1046,
      1.417,
      1.003,
      1.0711,
      1.1663,
      2.9869,
      1.9055,
      5.4022,
      1.1851,
      1.4833,
      1.0982,
      1.9849,
      1.0009,
      1.1734,
      1.1879,
      2.9263,
      2.0645,
      4.1182,
      1.1795,
      1.4162,
      1.2466,
      1.4436,
      1.0015,
      1.0628,
      1.3803,
      2.3118,
      2.111,
      1.7237,
      1.0,
      1.0963,
      1.6761,
      3.0007,
      1.1035,
      1.5906,
      1.19,
      1.2588,
      1.7613,
      1.4155,
      1.816,
      3.0989,
      3.9512,
      1.8473,
      1.8363,
      1.3594,
      1.0008,
      2.1163,
      1.7147,
      3.1708,
      1.2373,
      1.3349,
      1.1635,
      1.4436,
      1.0003,
      1.1937,
      1.597,
      1.8831,
      2.3934,
      7.4595,
      1.154,
      1.4909,
      1.1484,
      1.4731,
      1.0003,
      1.1566,
      1.3526,
      4.0729,
      2.4123,
      1.8149,
      1.0,
      1.3599,
      1.674,
      3.7038,
      1.1216,
      2.1476,
      1.7599,
      1.9248,
      1.9128,
      2.2686,
      1.026,
      1.5046,
      1.7144,
      2.15,
      1.0574,
      1.8629,
      1.2002,
      1.5241,
      2.2725,
      3.9424,
      1.9908,
      1.3795,
      1.1271,
      1.9814,
      1.0024,
      1.4112,
      1.067,
      3.2764
    ],
    "max": 7.4595,
    "min": 1.0,
    "mean": 1.8703
  },
  "attention": {
    "mean_entropy": null,
    "per_layer": null,
    "per_head": null,
    "high_entropy_heads": [],
    "note": "Attention weights not available via Ollama API. Use transformers library with output_attentions=True for direct model access to attention patterns."
  },
  "surprisal": {
    "mean": 0.747,
    "per_token": [
      1.6035,
      1.0313,
      0.0,
      0.1007,
      1.2273,
      2.3028,
      0.0051,
      0.8507,
      1.8564,
      0.4545,
      1.0713,
      1.0081,
      0.0,
      0.0748,
      1.1617,
      1.1434,
      0.6077,
      0.5727,
      1.1613,
      1.4433,
      0.6679,
      1.0443,
      0.0749,
      0.0322,
      0.4072,
      1.2853,
      0.9505,
      1.3533,
      0.0273,
      0.0163,
      0.7327,
      0.9124,
      0.0346,
      0.4773,
      1.2766,
      1.4401,
      2.5487,
      1.1218,
      0.2117,
      1.441,
      0.6265,
      2.1514,
      0.1681,
      0.7178,
      0.0921,
      0.7042,
      0.0005,
      0.4004,
      0.1818,
      1.6904,
      0.8004,
      1.9793,
      0.192,
      0.5578,
      0.1435,
      0.5029,
      0.0044,
      0.0992,
      0.2219,
      1.5786,
      0.9301,
      2.4335,
      0.245,
      0.5689,
      0.1351,
      0.9891,
      0.0014,
      0.2307,
      0.2484,
      1.5491,
      1.0458,
      2.042,
      0.2382,
      0.502,
      0.318,
      0.5297,
      0.0021,
      0.0879,
      0.4649,
      1.209,
      1.0779,
      0.7855,
      0.0,
      0.1327,
      0.7451,
      1.5853,
      0.1421,
      0.6696,
      0.251,
      0.3321,
      0.8166,
      0.5013,
      0.8608,
      1.6318,
      1.9823,
      0.8854,
      0.8768,
      0.443,
      0.0011,
      1.0815,
      0.778,
      1.6649,
      0.3072,
      0.4168,
      0.2185,
      0.5297,
      0.0004,
      0.2554,
      0.6754,
      0.9131,
      1.259,
      2.8991,
      0.2066,
      0.5762,
      0.1996,
      0.5588,
      0.0005,
      0.2099,
      0.4357,
      2.0261,
      1.2704,
      0.8599,
      0.0,
      0.4435,
      0.7433,
      1.889,
      0.1655,
      1.1027,
      0.8155,
      0.9447,
      0.9357,
      1.1818,
      0.037,
      0.5893,
      0.7777,
      1.1043,
      0.0805,
      0.8975,
      0.2633,
      0.6079,
      1.1843,
      1.9791,
      0.9934,
      0.4642,
      0.1726,
      0.9865,
      0.0035,
      0.4969,
      0.0936,
      1.7121
    ],
    "high_surprisal_tokens": []
  },
  "activations": {
    "per_layer_norm": null,
    "variance_per_layer": null,
    "note": "Internal activations not available via Ollama API. Use transformers library with output_hidden_states=True for direct model access to layer activations."
  },
  "comparative": {
    "baseline": "traditional_mean",
    "perplexity_zscore": -0.0123,
    "entropy_zscore": 0.0269,
    "surprisal_zscore": 0.0269,
    "outlier_flags": [],
    "classification": "statistically_normal",
    "interpretation": "This piece falls well within the normal range of the model's experience with musical notation. All metrics indicate familiar, predictable patterns."
  }
}